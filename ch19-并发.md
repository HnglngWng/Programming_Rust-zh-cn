# 并发(Concurrency)

> 从长远来看,用面向机器的语言编写大型并发程序是不可取的,因为这种语言允许不受限制地使用存储位置及其地址.我们无法使这样的程序可靠(即使有复杂的硬件机制的帮助).
> --Per Brinch Hansen (1977)
> 通信模式是并行模式.
> --Whit Morriss

原文

> In the long run it is not advisable to write large concurrent programs in machine-oriented languages that permit unrestricted use of store locations and their addresses. There is just no way we will be able to make such programs reliable (even with the help of complicated hardware mechanisms).
> --Per Brinch Hansen (1977)
>
> Patterns for communication are patterns for parallelism.
> --Whit Morriss

如果你对并发的态度在你的职业生涯中发生了变化,那么你并不孤单.这是一个常见的故事.

首先,编写并发代码既简单又有趣.这些工具--线程,锁,队列等等--很容易获取和使用.这里面有很多陷阱,这是真的,但幸运的是你知道它们都是什么,并且小心翼翼地避免犯错误.

在某些时候,你必须调试其他人的多线程代码,你不得不得出这样的结论:有些人确实不应该使用这些工具.

然后在某些时候,你必须调试自己的多线程代码.

经验灌输了对所有多线程代码的健康的怀疑,如果不是彻头彻尾的不信任.偶尔有一篇文章解释为什么一些明显正确的多线程习惯用法根本不起作用.(它与"内存模型(the memory model)"有关.)但是你最终会找到一种并发的方法,你认为你可以实际使用它,而不会经常出错.你可以把几乎所有东西都塞进那个习惯用法中,并且(如果你 *真的(really)* 很优秀的话)你学会对增加复杂性说"不(no)".

当然,还有很多习语.系统程序员通常使用的方法包括以下内容:

- 一个只有单个工作(job)的 *后台线程(background thread)* ,它会定期醒来执行.

- 通用 *任务队列(task queues)* 与客户端通信的通用 *工作池(worker pools)* .

- 数据从一个线程流向下一个线程的 *管道(Pipelines)* .每个线程做一点工作.

- *数据并行性(Data parallelism)* ,假定(正确或错误地)整个计算机将主要进行一个大型计算,因此将其分成`n`个部分,并在`n`个线程上运行,以期将机器的所有`n`个核心同时工作.

- *同步对象之海(sea of synchronized objects)* ,其中多个线程可以访问相同的数据,并且使用基于低级原语(如互斥锁)的临时锁方案来避免竞争.(Java包含对此模型的内置支持,这在20世纪90年代和21世纪初非常流行.)

- *原子整数操作(Atomic integer operations)* 允许多个核通过一个机器字大小的字段传递信息来进行通信.(这比其他方法更难得到正确的结果,除非交换的数据只是整数值.在实践中,它通常是指针.)

随着时间的推移,你可能会使用其中的几种方法并将它们安全地结合起来.你是这门艺术的大师.如果不允许其他人以任何方式修改系统,事情会很棒.良好地使用线程的程序充满了不成文的规则(unwritten rules).

Rust提供了一种更好的使用并发的方式,而不是强制所有程序采用单一风格(对于系统程序员来说,这根本不是解决方案),而是通过安全地支持多种风格.不成文的规则是写下来的--在代码中--并由编译器强制执行.

你已经听说Rust允许你编写安全,快速,并发的程序.这一章我们会告诉你怎么做.我们将介绍使用Rust线程的三种方法:

- Fork-join并行性(Fork-join parallelism)

- 通道(Channels)

- 共享可变状态(Shared mutable state)

在此过程中,你将使用迄今为止所学到的关于Rust语言的所有内容.在单线程程序中,Rust对引用,可变性和生命周期的关注是有价值的,但是在并发编程中,这些规则的真正意义变得明显.它们可以扩展你的工具箱,快速,正确地破解多种风格的多线程代码--无需怀疑,无需不信任,无需担心.

## Fork-join并行性(Fork-Join Parallelism)

当我们有几个完全独立的任务,我们想要同时执行时,最简单的线程用例就会出现.

例如,假设我们正在对大量文档进行自然语言处理.我们可以写一个循环:

```Rust
fn process_files(filenames: Vec<String>) -> io::Result<()> {
    for document in filenames {
        let text = load(&document)?;  // read source file
        let results = process(text);  // compute statistics
        save(&document, results)?;    // write output file
    }
    Ok(())
}
```

该程序将如图19-1所示运行.

*图19-1. process_files()的单线程执行*

由于每个文档都是单独处理的,因此通过将语料库分成块并在单独的线程上处理每个块来加快此任务相对容易,如图19-2所示.

此模式称为 *fork-join并行性(fork-join parallelism)* . *fork* 是为了启动一个新线程,而 *join* 一个线程就是等待它完成.我们已经看过这种技术:我们用它来加速第2章中的Mandelbrot程序.

*图19-2. 使用fork-join方法进行多线程文件处理*

Fork-join并行性很有吸引力,原因如下:

- 这很简单.Fork-join易于实现,Rust可以很容易地实现.

- 它避免了瓶颈.fork-join中没有共享资源的锁定.任何线程必须等待另一个线程的唯一时间是在最后.与此同时,每个线程都可以自由运行.这有助于将任务切换(task-switching)开销降低.

- 性能数学计算很简单.在最好的情况下,通过启动四个线程,我们可以在四分之一的时间内完成我们的工作.图19-2显示了我们不应期望这种理想加速的一个原因:我们可能无法在所有线程上均匀分配工作.另一个需要注意的原因是,有时fork-join程序必须在线程加入后花费一些时间,并 *结合(combining)* 线程计算的结果.也就是说,完全隔离任务可能会带来一些额外的工作.尽管如此,除了这两件事之外,任何具有独立工作单元的CPU限制程序都可以获得显着提升.

- 很容易推断出程序的正确性.只要线程确实是独立的,fork-join程序就是 *确定性的(deterministic)* ,就像Mandelbrot程序中的计算线程一样.无论线程速度如何变化,程序始终都会产生相同的结果.这是一个没有竞争条件的并发模型.

fork-join的主要缺点是它需要独立的工作单元.在本章的后面部分,我们将考虑一些不能如此清晰地分解的问题.

现在,让我们坚持使用自然语言处理示例.我们将展示一些将fork-join模式应用于`process_files`函数的方法.

### spawn和join(spawn and join)

函数`std::thread::spawn`启动一个新线程.

```Rust
spawn(|| {
    println!("hello from a child thread");
})
```

它接受一个参数,一个`FnOnce`闭包或函数.Rust启动一个新线程来运行该闭包或函数的代码.新线程是一个真正的操作系统线程,它有自己的堆栈,就像C++,C#和Java中的线程一样.

这是一个更实际的例子,使用`spawn`实现一个之前`process_files`函数的并行版本:

```Rust
use std::thread::spawn;

fn process_files_in_parallel(filenames: Vec<String>) -> io::Result<()> {
    // Divide the work into several chunks.
    const NTHREADS: usize = 8;
    let worklists = split_vec_into_chunks(filenames, NTHREADS);

    // Fork: Spawn a thread to handle each chunk.
    let mut thread_handles = vec![];
    for worklist in worklists {
        thread_handles.push(
            spawn(move || process_files(worklist))
        );
    }

    // Join: Wait for all threads to finish.
    for handle in thread_handles {
        handle.join().unwrap()?;
    }

    Ok(())
}
```

让我们逐行分析这个函数.

```Rust
fn process_files_in_parallel(filenames: Vec<String>) -> io::Result<()> {
```

我们的新函数与原始`process_files`具有相同的类型签名,使其成为一个方便的替代品.

```Rust
// Divide the work into several chunks.
const NTHREADS: usize = 8;
let worklists = split_vec_into_chunks(filenames, NTHREADS);
```

我们使用一个工具函数`split_vec_into_chunks`(此处未显示)来划分工作.结果(`worklists`)是向量的向量.它包含八个大小均匀的原始向量`filenames`切片.

```Rust
// Fork: Spawn a thread to handle each chunk.
let mut thread_handles = vec![];
for worklist in worklists {
    thread_handles.push(
        spawn(move || process_files(worklist)
    );
}
```

我们为每个`worklist.spawn()`生成一个线程,返回一个名为`JoinHandle`的值,稍后我们将使用它.

现在,我们将所有`JoinHandle`放入向量中.

注意我们如何将文件名列表添加到工作线程中:

- `worklist`由父线程中的`for`循环定义和填充.

- 一旦创建了`move`闭包,就会将`worklist`移动到闭包中.

- `spawn`然后将闭包(包括`worklist`向量)移动到新的子线程.

这些移动很便宜.就像我们在第4章中讨论过的`Vec<String>`移动一样,`String`没有被克隆.事实上,没有任何东西被分配或释放.移动的唯一数据是`Vec`本身:三个机器字.

你创建的大多数线程都需要代码和数据才能开始.方便地,Rust闭包包含你想要的任何代码以及你想要的任何数据.

继续:

```Rust
// Join: Wait for all threads to finish.
for handle in thread_handles {
    handle.join().unwrap()?;
}
```

我们使用前面收集的`JoinHandle`的`.join()`方法等待所有八个线程完成.连接线程通常是正确性所必需的,因为一旦`main`返回,Rust程序就会退出,即使其他线程仍在运行.没有调用析构函数;额外的线程刚被杀死.如果这不是你想要的,请确保在从`main`返回之前加入你关心的任何线程.

如果我们设法完成此循环,则意味着所有八个子线程都已成功完成.因此,我们的函数以返回`Ok(())`结束:

```Rust
    Ok(())
}
```

### 跨线程错误处理(Error Handling Across Threads)

由于错误处理,我们在示例中用于连接子线程的代码比它看起来更复杂.让我们重新审视这行代码:

```Rust
handle.join().unwrap()?;
```

`.join()`方法为我们做了两件好事.

首先,`handle.join()`返回一个`std::thread::Result`, *如果子线程出现恐慌(if the child thread panicked)* ,则返回一个错误.这使得Rust中的线程比C++中的线程更健壮.在C++中,越界数组访问是未定义行为,并且没有保护系统的其余部分免受后果影响.在Rust中,恐慌是安全的,每个线程的.线程之间的界限充当恐慌的防火墙;恐慌不会自动从一个线程传播到依赖它的线程.相反,一个线程中的恐慌被报告为其他线程中的错误`Result`.整个程序很容易恢复.

但是,在我们的程序中,我们不尝试任何花哨的恐慌处理.相反，我们立即在此`Result`上使用`.unwrap()`,断言它是`Ok`结果而不是`Err`结果.如果一个子线程 *出现(did)* 恐慌,那么这个断言就会失败,所以父线程也会出现恐慌.我们显式地将恐慌从子线程传播到父线程.
